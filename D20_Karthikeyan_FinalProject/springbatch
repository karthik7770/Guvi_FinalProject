public class GroupedRecordItemReader implements ItemReader<GroupedRecord> {
    private final JdbcTemplate jdbcTemplate;
    private List<GroupedRecord> groupedRecords;
    private int nextIndex;

    public GroupedRecordItemReader(JdbcTemplate jdbcTemplate) {
        this.jdbcTemplate = jdbcTemplate;
        this.nextIndex = 0;
    }

    @Override
    public GroupedRecord read() {
        if (groupedRecords == null) {
            groupedRecords = fetchGroupedRecords();
        }
        if (nextIndex < groupedRecords.size()) {
            return groupedRecords.get(nextIndex++);
        }
        return null; // end of reading
    }

    private List<GroupedRecord> fetchGroupedRecords() {
        List<Record> records = jdbcTemplate.query("SELECT * FROM your_table ORDER BY recId", new RecordRowMapper());
        Map<String, GroupedRecord> groupedRecordMap = new LinkedHashMap<>();
        for (Record record : records) {
            groupedRecordMap
                .computeIfAbsent(record.getRecId(), k -> new GroupedRecord(k, new ArrayList<>()))
                .getRecords()
                .add(record);
        }
        return new ArrayList<>(groupedRecordMap.values());
    }
}
public class GroupedRecord {
    private String recId;
    private List<Record> records;
//org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'entityManagerFactory' defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: Unable to create requested service [org.hibernate.engine.jdbc.env.spi.JdbcEnvironment] due to: Unable to determine Dialect without JDBC metadata (please set 'jakarta.persistence.jdbc.url' for common cases or 'hibernate.dialect' when a custom Dialect implementation must be provided)
    // getters and setters
//org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar [SELECT JOB_INSTANCE_ID, JOB_NAME
//FROM BATCH_JOB_INSTANCE
//WHERE JOB_NAME = ?
// and JOB_KEY = ?]
}
@Bean
	public Job mainJob(JobRepository jobRepository,
	@Qualifier("pdtTransactionManager") PlatformTransactionManager pdtTransactionManager) throws Exception {
		JobBuilder jobBuilder = new JobBuilder("mainJob", jobRepository);
		return jobBuilder.incrementer(new RunIdIncrementer())
 
				.start(provLocationStep(jobRepository, pdtTransactionManager)).on("COMPLETED").to(healthCareServiceStep(jobRepository, pdtTransactionManager))
				.from(healthCareServiceStep(jobRepository, pdtTransactionManager)).on("COMPLETED").to(healthCareService2Step(jobRepository,pdtTransactionManager))
				.from(healthCareService2Step(jobRepository,pdtTransactionManager)).on("COMPLETED").to(qualificationEntityStep(jobRepository, pdtTransactionManager))
				.from(qualificationEntityStep(jobRepository, pdtTransactionManager)).on("COMPLETED").to(organizationStep(jobRepository,pdtTransactionManager))
				.from(organizationStep(jobRepository, pdtTransactionManager)).on("COMPLETED").to(practionerStep(jobRepository, pdtTransactionManager))
				.from(practionerStep(jobRepository,pdtTransactionManager)).on("COMPLETED").to(provOrgAffiliationStep(jobRepository, pdtTransactionManager))
				.from(provOrgAffiliationStep(jobRepository, pdtTransactionManager)).on("COMPLETED").to(practionerRoleStep(jobRepository, pdtTransactionManager))
				.from(practionerRoleStep(jobRepository, pdtTransactionManager)).end().build();
	}
SimpleStepBuilder<TrgrResponse, TrgrResponse> builder = ((SimpleStepBuilder<TrgrResponse, TrgrResponse>) stepBuilderFactory
				.get("fromFileIntoDatabase").<TrgrResponse, TrgrResponse>chunk(chunksize)
				.reader(pdtProvLocReader)
				.processor(pdtProvLocProcessor.asyncItemProcessor())
				.writer(pdtProvLocWriter.asyncItemWriter())
				.taskExecutor(new SimpleAsyncTaskExecutor()).transactionManager(getTransactionManager()))
				.faultTolerant()                .skip(Exception.class) 
                .skipLimit(Integer.MAX_VALUE).taskExecutor(pdtExecuter)
                .throttleLimit(8).
                listener(skipListener());
